{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.29 ðŸš€ Python-3.12.3 torch-2.5.1+cu124 CPU (AMD Ryzen 5 7640U w/ Radeon 760M Graphics)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/david-wang/Desktop/Projects/Wisconsin Robotics/YOLO11/yolo_labeled_data/valid/labels... 157 images, 31 backgrounds, 0 c\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/david-wang/Desktop/Projects/Wisconsin Robotics/YOLO11/yolo_labeled_data/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14<00:00,  4.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        157        140      0.865      0.812       0.88      0.758\n",
      "                bottle        122        129      0.958      0.715      0.876      0.696\n",
      "                hammer         11         11      0.772      0.909      0.883      0.821\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validate the model\n",
    "best_model = YOLO(\"trained_models/yolo11n_best.pt\")\n",
    "metrics = best_model.val(data='yolo_labeled_data/data.yaml', batch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 bottle, 29.5ms\n",
      "Speed: 4.0ms preprocess, 29.5ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "# Test the model on an image\n",
    "results = best_model([\"test.jpg\"])\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # Display to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\test.jpg: 640x480 1 bottle, 70.8ms\n",
      "Speed: 11.4ms preprocess, 70.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 c:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\test.jpg: 640x480 1 bottle, 70.8ms\n",
      "Speed: 3.7ms preprocess, 70.8ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "yolo11n - Time: 0.36s, Memory: 1804.79 MiB\n",
      "\n",
      "image 1/1 c:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\test.jpg: 640x480 1 bottle, 150.4ms\n",
      "Speed: 6.2ms preprocess, 150.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 c:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\test.jpg: 640x480 1 bottle, 148.0ms\n",
      "Speed: 0.0ms preprocess, 148.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "yolo11s - Time: 0.52s, Memory: 1877.91 MiB\n",
      "\n",
      "image 1/1 c:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\test.jpg: 640x480 1 bottle, 309.0ms\n",
      "Speed: 11.2ms preprocess, 309.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 c:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\test.jpg: 640x480 1 bottle, 306.2ms\n",
      "Speed: 11.6ms preprocess, 306.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "yolo11m - Time: 0.81s, Memory: 1975.52 MiB\n",
      "\n",
      "image 1/1 c:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\test.jpg: 640x480 1 bottle, 372.9ms\n",
      "Speed: 2.4ms preprocess, 372.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 c:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\test.jpg: 640x480 1 bottle, 384.0ms\n",
      "Speed: 0.0ms preprocess, 384.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "yolo11l - Time: 0.94s, Memory: 2028.05 MiB\n",
      "\n",
      "image 1/1 c:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\test.jpg: 640x480 1 bottle, 739.0ms\n",
      "Speed: 0.0ms preprocess, 739.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 c:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\test.jpg: 640x480 1 bottle, 705.7ms\n",
      "Speed: 1.5ms preprocess, 705.7ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "yolo11x - Time: 1.80s, Memory: 2128.78 MiB\n"
     ]
    }
   ],
   "source": [
    "# Benchmark different versions of YOLO11\n",
    "\n",
    "# Import libraries\n",
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# Import all YOLO11 models\n",
    "yolo11n = YOLO(\"yolo11n.pt\")\n",
    "yolo11s = YOLO(\"yolo11s.pt\")\n",
    "yolo11m = YOLO(\"yolo11m.pt\")\n",
    "yolo11l = YOLO(\"yolo11l.pt\")\n",
    "yolo11x = YOLO(\"yolo11x.pt\")\n",
    "models = [yolo11n, yolo11s, yolo11m, yolo11l, yolo11x]\n",
    "names = [\"yolo11n\", \"yolo11s\", \"yolo11m\", \"yolo11l\", \"yolo11x\"]\n",
    "\n",
    "# Benchmark function\n",
    "def benchmark(model, image):\n",
    "  # Inference time\n",
    "  start = time.time()\n",
    "  model.predict(image)\n",
    "  end = time.time()\n",
    "  t = end - start\n",
    "\n",
    "  # Memory usage\n",
    "  memory = memory_usage((model.predict, (image,)), max_usage=True)\n",
    "\n",
    "  return t, memory\n",
    "\n",
    "# Benchmark all models\n",
    "for model, name in zip(models, names):\n",
    "  t, memory = benchmark(model, \"test.jpg\")\n",
    "  print(f\"{name} - Time: {t:.2f}s, Memory: {memory:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.23  Python-3.11.7 torch-2.5.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\yolo_labeled_data\\valid\\labels.cache... 101 images, 31 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        101         84      0.847      0.681       0.79      0.594\n",
      "                bottle         66         73      0.815      0.699       0.76      0.553\n",
      "                hammer         11         11      0.879      0.663       0.82      0.635\n",
      "Speed: 2.3ms preprocess, 7.5ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validate fine-tuned model 1\n",
    "model = YOLO(\"trained_models/fine-tuning1_best.pt\")\n",
    "metrics = model.val(data='yolo_labeled_data/data.yaml', batch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.23  Python-3.11.7 torch-2.5.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\yolo_labeled_data\\valid\\labels.cache... 101 images, 31 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:15<00:00,  7.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        101         84      0.937      0.875      0.927        0.8\n",
      "                bottle         66         73      0.901       0.75      0.859      0.697\n",
      "                hammer         11         11      0.973          1      0.995      0.904\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validate fine-tuned model 2\n",
    "model = YOLO(\"trained_models/fine-tuning2_best.pt\")\n",
    "metrics = model.val(data='yolo_labeled_data/data.yaml', batch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.23  Python-3.11.7 torch-2.5.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "YOLO11x summary (fused): 464 layers, 56,829,334 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\yolo_labeled_data\\valid\\labels.cache... 101 images, 31 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:09<00:00, 34.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        101         84      0.888      0.834      0.915      0.686\n",
      "                bottle         66         73       0.79      0.849      0.864       0.68\n",
      "                hammer         11         11      0.985      0.818      0.967      0.693\n",
      "Speed: 2.4ms preprocess, 624.9ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validate fine-tuned model 3\n",
    "model = YOLO(\"trained_models/fine-tuning3_best.pt\")\n",
    "metrics = model.val(data='yolo_labeled_data/data.yaml', batch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.23  Python-3.11.7 torch-2.5.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "YOLO11x summary (fused): 464 layers, 56,829,334 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\yolo_labeled_data\\valid\\labels.cache... 101 images, 31 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:22<00:00, 41.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        101         84      0.974      0.949      0.989      0.761\n",
      "                bottle         66         73      0.947      0.945      0.983      0.782\n",
      "                hammer         11         11          1      0.954      0.995      0.739\n",
      "Speed: 10.9ms preprocess, 685.3ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validate fine-tuned model 4\n",
    "model = YOLO(\"trained_models/fine-tuning4_best.pt\")\n",
    "metrics = model.val(data='yolo_labeled_data/data.yaml', batch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.23  Python-3.11.7 torch-2.5.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\david\\OneDrive\\Desktop\\Projects\\Wisconsin Robotics\\YOLO11\\yolo_labeled_data\\valid\\labels.cache... 101 images, 31 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        101         84          1      0.947      0.983      0.854\n",
      "                bottle         66         73          1      0.901      0.972      0.824\n",
      "                hammer         11         11          1      0.992      0.995      0.883\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validate fine-tuned model 5\n",
    "model = YOLO(\"trained_models/fine-tuning5_best.pt\")\n",
    "metrics = model.val(data='yolo_labeled_data/data.yaml', batch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.29 ðŸš€ Python-3.12.3 torch-2.5.1+cu124 CPU (AMD Ryzen 5 7640U w/ Radeon 760M Graphics)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/david-wang/Desktop/Projects/Wisconsin Robotics/YOLO11/yolo_labeled_data/valid/labels.cache... 157 images, 31 background\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:25<00:00,  8.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        157        140      0.976      0.955      0.977      0.786\n",
      "                bottle        122        129          1      0.909      0.959      0.756\n",
      "                hammer         11         11      0.951          1      0.995      0.817\n",
      "Speed: 1.5ms preprocess, 76.9ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validate fine-tuned model 6\n",
    "model = YOLO(\"trained_models/fine-tuning6_best.pt\")\n",
    "metrics = model.val(data='yolo_labeled_data/data.yaml', batch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
